{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "lab53_sentiment_analysis_naver_movie_rev100.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TI5-Fx_zPO0Y"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rtajeong/AI_Cluster/blob/main/lab53_sentiment_analysis_naver_movie_rev100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI5-Fx_zPO0Y"
      },
      "source": [
        "네이버영화평점\n",
        "==\n",
        "- 감성분석\n",
        "- 네이버 영화평점 (Naver sentiment movie corpus v.1.0) 데이터(https://github.com/e9t/nsmc)\n",
        "- 영화 리뷰 20만건이 저장됨. 각 평가 데이터는 0(부정), 1(긍정)으로 label 됨.\n",
        "\n",
        "### 한글 자연어 처리\n",
        "- KoNLPy(“코엔엘파이”라고 읽습니다)는 한국어 정보처리를 위한 파이썬 패키지입니다.\n",
        "- konlpy 패키지에서 제공하는 Twitter라는 문서 분석 라이브러리 사용 (트위터 분석 뿐 아니라 한글 텍스트 \n",
        "  처리도 가능)\n",
        "- colab 사용 권장"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZNLuzYoPO0k"
      },
      "source": [
        "# 로지스틱회귀를 이용한 감성분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8ZDSK7xQfmD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c45ab8a8-556a-49fd-ca62-597b5c9e366b"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr1Rds4XQn2N",
        "outputId": "7a0513e0-b57c-4bb6-8c65-be70a10e9844"
      },
      "source": [
        "# 네이버 영화 평점 데이터 다운로드\n",
        "!curl -L https://bit.ly/2X9Owwr -o ratings_train.txt\n",
        "!curl -L https://bit.ly/2WuLd5I -o ratings_test.txt"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   152  100   152    0     0    899      0 --:--:-- --:--:-- --:--:--   899\n",
            "100   148    0   148    0     0    397      0 --:--:-- --:--:-- --:--:--  1129\n",
            "100   318  100   318    0     0    536      0 --:--:-- --:--:-- --:--:--   536\n",
            "100 14.0M  100 14.0M    0     0  11.6M      0  0:00:01  0:00:01 --:--:-- 11.6M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   151  100   151    0     0   3282      0 --:--:-- --:--:-- --:--:--  3282\n",
            "100   147    0   147    0     0    781      0 --:--:-- --:--:-- --:--:--   781\n",
            "100   318  100   318    0     0    809      0 --:--:-- --:--:-- --:--:--   809\n",
            "100 4827k  100 4827k    0     0  5485k      0 --:--:-- --:--:-- --:--:--  122M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqXWg0fAPO0l",
        "scrolled": true
      },
      "source": [
        "import konlpy\n",
        "import pandas as pd\n",
        "from konlpy.tag import Twitter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.pipeline import make_pipeline\n",
        "# import pickle\n",
        "# import os.path\n",
        "\n",
        "# 데이터 로드\n",
        "# keep_default_na: Whether or not to include the default NaN values when parsing the data\n",
        "# -> False: no strings will be parsed as NaN.\n",
        "\n",
        "df_train = pd.read_csv('ratings_train.txt', delimiter='\\t', keep_default_na=False)\n",
        "df_test = pd.read_csv('ratings_test.txt', delimiter='\\t', keep_default_na=False)"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "sZYlqPNvvuTL",
        "outputId": "87ce0f5e-b274-49c9-f426-9b91c0315659"
      },
      "source": [
        "df_train.head(2)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                           document  label\n",
              "0  9976970                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1  3819312  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "SmKAgkvMCfwu",
        "outputId": "55395936-29be-4726-ca05-cef470cf23a0"
      },
      "source": [
        "df_test.head(2)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6270596</td>\n",
              "      <td>굳 ㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9274899</td>\n",
              "      <td>GDNTOPCLASSINTHECLUB</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id              document  label\n",
              "0  6270596                   굳 ㅋ      1\n",
              "1  9274899  GDNTOPCLASSINTHECLUB      0"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6czFe5D5MhgA"
      },
      "source": [
        "text_train, y_train = df_train['document'].values, df_train['label'].values\n",
        "text_test, y_test = df_test['document'].values, df_test['label'].values"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzn8-rhIV4qs",
        "outputId": "d5c276b7-3a68-4b6f-ce3b-f90e13581ea4"
      },
      "source": [
        "text_train.shape, text_test.shape   # too big"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((150000,), (50000,))"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjn5HJGFWBuF"
      },
      "source": [
        "text_train, y_train = text_train[:2000], y_train[:2000]\n",
        "text_test, y_test = text_test[:1000], y_test[:1000]"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1_eeFpFWYLu",
        "outputId": "6e8d1a0a-f3bc-46d3-d0c9-5a713f9d372c"
      },
      "source": [
        "text_train.shape, text_test.shape"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2000,), (1000,))"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy5fHajqPO0w"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "def twitter_tokenizer(text):\n",
        "    return Okt().morphs(text)\n",
        "\n",
        "cv = TfidfVectorizer(tokenizer=twitter_tokenizer, max_features = 1000, min_df=5)"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7eeTvGHPO04",
        "outputId": "d1ddab4e-9e1b-4936-e5ed-f75ccdd17e62"
      },
      "source": [
        "x_train = cv.fit_transform(text_train)\n",
        "x_test = cv.transform(text_test)\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2000, 794) (1000, 794) (2000,) (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z7NFXb_w4Uq",
        "outputId": "5085ac96-1821-4a01-f2a7-3dc9ee592565"
      },
      "source": [
        "print(cv.vocabulary_)\n",
        "print(cv.get_feature_names()[:10])"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'아': 432, '더빙': 211, '..': 13, '진짜': 693, '흠': 791, '...': 14, '포스터': 742, '보고': 326, '영화': 520, '줄': 680, '....': 15, '연기': 512, '너': 174, '추천': 716, '한': 760, '다': 194, '이야기': 579, '솔직히': 402, '재미': 622, '는': 190, '없다': 484, '평점': 741, '그': 119, '의': 555, '가': 60, '!': 0, '에서': 496, '했던': 777, '너무나도': 177, '막': 261, '3': 24, '세': 392, '부터': 360, '초등학교': 708, '1': 20, '8': 28, '.': 12, 'ㅋㅋㅋ': 50, '별': 321, '반개': 314, '도': 213, '아까': 433, '움': 542, '원작': 546, '긴장감': 145, '을': 553, '제대로': 656, '했다': 776, '아깝다': 436, '욕': 537, '나온다': 160, '연': 511, '기': 138, '이': 557, '몇': 289, '년': 181, '인지': 596, '정말': 653, '로': 253, '해도': 772, '그것': 120, '만': 263, '드라마': 229, '가족': 68, '못': 297, '하는': 751, '사람': 370, '네': 179, '액션': 465, '있는': 602, '안되는': 453, '?': 33, '꽤': 151, '볼': 344, '데': 212, '식': 422, '너무': 175, '걍': 89, '짱': 699, '이다': 563, '♥': 45, '마다': 257, '90년': 30, '자극': 608, '!!': 1, '감성': 76, '멜로': 285, '~': 43, '서': 387, '손': 401, '들': 231, '고': 105, '때': 238, '뻔': 366, '해': 771, '좋다': 667, '보다': 334, '보면': 336, '것': 99, '취향': 718, '은': 552, '에': 492, '극장': 134, '본': 341, '중': 681, '가장': 67, '노잼': 184, '감동': 75, '임': 599, '스토리': 411, '되고': 219, 'ㅠㅠ': 57, '참': 702, '면': 286, '코': 722, '라고': 244, '이라고': 566, '그냥': 121, '난': 164, '처럼': 705, '인': 589, '이해': 587, '하는데': 753, '왜': 533, '갈수록': 72, '이건': 558, '캐스팅': 721, '과': 110, '하': 746, '지': 684, '않은': 457, '내': 170, '잘': 617, '자': 607, '를': 256, '위': 547, ',': 9, '이라': 565, '저': 638, '놈': 185, '절대': 646, '아닌': 441, '걸': 96, '요': 535, '나름': 157, '듯': 232, '보면서': 337, '않는': 455, '건': 93, '재미없다': 625, '지루하고': 686, '같은': 81, '인데': 593, '하고': 748, '넘': 178, '있고': 601, '보는': 329, ';': 31, '게': 100, '별로': 322, '안': 452, '나오고': 158, '이라도': 568, '구': 113, '나옴': 161, 'ㅡㅡ': 59, '수작': 404, '주제': 677, '지루하다': 687, '야': 466, '그래서': 126, '할': 767, '수': 403, '꼭': 150, '2': 23, '연출': 515, '력': 252, '9': 29, '점': 647, '다시': 196, '한번': 765, '적': 639, '남': 166, '님': 193, '좋았어요': 671, '완전': 532, '쓰레기': 429, '도안': 215, 'ㅋㅋ': 49, '시간': 415, '아까워': 435, '재밌는데': 633, '이리': 574, '라도': 247, '입니다': 600, '아직도': 451, '인생': 595, '최고': 712, '대한': 207, '대체': 206, '정신': 654, '관객': 111, '이네': 562, '이렇게': 572, '평가': 739, '모르겠다': 292, '매력': 278, \"'\": 6, '인가': 590, '내용': 172, '없고': 481, '하나': 750, '없음': 488, 'ㅇ': 46, '맘': 274, '또': 241, '방법': 316, '이라는': 567, '멋진': 284, '배우': 318, '하게': 747, '일': 597, '잔잔한': 616, '합니다': 770, '음악': 554, '조금': 660, '주고': 674, '10': 21, '^^': 36, '돈': 216, '큰': 725, '공감': 107, '캐릭터': 720, '상': 379, '였음': 517, '극': 133, '초반': 709, '엔': 501, '가면': 63, 'ㅋ': 48, '수준': 405, '딱': 236, '알': 458, 'ㅉㅉ': 47, '우리': 539, '사랑': 371, '나도': 155, '싶다': 427, '이랑': 570, '이나': 560, '소설': 398, '속': 400, '에선': 499, '제일': 659, '라': 243, '터': 728, '(': 7, '용': 538, ')': 8, '웃음': 544, '감독': 74, '-': 11, '말': 272, '했음': 778, '작은': 614, '맛': 275, '가슴': 65, '있을까': 604, '자체': 611, '무슨': 300, 'oo': 39, '혼자': 783, '재미있어요': 629, '전': 640, '기분': 141, '느낌': 189, '없는': 482, '그저': 132, '생각': 385, '언제': 477, '보는내내': 331, '그대로': 123, '나와서': 162, '중간': 682, '계속': 104, '주인공': 676, '소': 395, '모습': 294, '짜증': 698, 'ㅜㅜ': 55, '전개': 641, '좀': 664, '빨리': 365, '감정': 77, '많은': 270, '다큐': 198, '우리나라': 540, '슬픈': 412, '대해': 208, '깊이': 146, '바로': 312, '위해': 548, '노력': 183, '이정': 583, '이야': 578, '살인': 376, '어디': 470, '예전': 526, '작품': 615, '삼': 378, '산': 374, '으로': 550, '시청률': 421, '이제': 584, '짜리': 697, '연기력': 513, '몰입도': 296, '에도': 495, '분': 361, '한테': 766, '일본': 598, '이런': 571, '건가': 94, '??': 34, '봤어요': 356, '재밌어요': 635, '근데': 136, '하려고': 755, '하면': 756, '집': 696, '그런': 128, '그래도': 125, '졸작': 663, '라서': 249, '더': 210, '결말': 103, '냐': 173, '매우': 279, '실망': 424, '.....': 16, '한국영': 762, '화': 784, '뭐': 304, '시작': 418, '먹고': 283, '에게': 493, '뭘': 307, '엉망': 491, '개': 85, '별루': 323, '였다': 516, '기대': 139, '되는': 220, '가요': 66, '눈': 187, '성룡': 391, '최악': 714, 'ㅋㅋㅋㅋ': 51, 'ㅋㅋㅋㅋㅋ': 52, '여': 503, '인상': 594, '와': 530, '에요': 500, '본거': 342, '설정': 389, '재밌고': 631, '새로운': 383, '재밌음': 636, '미': 308, '대박': 204, '재미없음': 626, '진심': 692, '나': 154, '두': 226, '인거': 592, '술': 407, '킬링타임': 727, '재미있게': 627, '봤습니다': 355, ';;': 32, '처음': 706, '로맨스': 254, ',,': 10, '아주': 449, '머': 280, '명작': 288, '재밌게': 630, '봤다': 353, '너무나': 176, '소재': 399, '끌': 152, '지만': 690, '몰입': 295, '보지마라': 340, '특유': 730, '현': 780, '실감': 423, '도대체': 214, '까지': 147, '따뜻한': 235, '생애': 386, '전부': 642, '하다': 754, '후': 789, '아니': 437, '대': 202, '보게': 325, '된': 223, '봐도': 347, '또한': 242, '문제': 301, '아니라': 440, '전혀': 645, '그리고': 130, '같음': 83, '~~': 44, '있음': 605, '어느': 469, '......': 17, '재미있고': 628, '영': 518, '당시': 200, '상황': 382, '그만': 131, '잼': 637, '건지': 95, '많이': 271, '성': 390, '어떤': 472, '에서도': 498, '보기': 328, '정도': 652, '본다': 343, '마지막': 260, '하지만': 759, '마세요': 258, '어떻게': 473, '살': 375, '나를': 156, '나이': 163, '작가': 613, '답': 199, '여운': 506, '남는': 168, '질': 695, '충분히': 717, '개인': 88, '역시': 510, '괜찮은': 112, '좋은': 672, '???': 35, '자신': 610, '어린이': 474, '어릴': 475, '이란': 569, '한국': 761, '오랜': 529, '봤네요': 351, '되어': 221, '오늘': 528, '완성': 531, '요즘': 536, '막장': 262, '화이팅': 787, '조절': 661, '사극': 369, '그녀': 122, '왠지': 534, '코미디': 723, '장면': 621, '\"': 4, '끝': 153, '쯤': 700, '한마디': 764, '\"\"': 5, '같다': 79, '!!!': 2, '하기': 749, '이유': 582, '니': 191, '하지': 758, '게임': 101, '않고': 454, 'cg': 38, '배경': 317, '예산': 524, '모르고': 293, '알바': 459, '4': 25, '라니': 246, '아름다운': 442, '남자': 169, '애': 462, '시종일관': 419, '상당히': 380, '!!!!': 3, '얼마나': 479, '밖에': 313, '아무': 443, '보지': 339, '티비': 733, '판': 734, '거': 90, '피': 744, '하는게': 752, '아니다': 439, '유치하고': 549, '류': 255, '어': 468, '옛날': 527, '생': 384, '봤던': 354, '추억': 715, '기존': 144, '후회': 790, '이영화': 581, '보': 324, '니까': 192, '없이': 489, '물': 302, '개봉': 86, 'ㅠ': 56, '허': 779, '청춘': 707, '순간': 406, 'tv': 42, '시리즈': 417, '아직': 450, '까지도': 148, '이고': 559, '표현': 743, '되지': 222, '시': 414, '등': 233, '히': 793, '면서': 287, '랑': 250, '원': 545, '래': 251, '해요': 774, '필요': 745, '봐라': 348, '다른': 195, '버렸다': 319, '구성': 114, '네이버': 180, '현실': 781, '그때': 124, '대사': 205, '없는데': 483, '동': 217, '급': 137, '마음': 259, '지루하지': 688, '보고싶은': 327, '비': 363, '코믹': 724, '에는': 494, '없었다': 487, 'ㅎㅎ': 54, '대가': 203, '귀신': 117, '댓글': 209, '봤지만': 357, '보는데': 332, '역': 508, '기도': 140, '전쟁': 644, '묘사': 298, '극장판': 135, '간': 70, '세계': 393, '역사': 509, '있다': 603, '딸': 237, '제발': 658, '책': 704, '미친': 309, '날': 165, '뿐': 367, '굿': 116, '같아요': 80, '제': 655, '작': 612, '.......': 18, '뭔가': 306, '부': 358, 'ooo': 40, '어디서': 471, '드': 228, '소리': 397, '스릴러': 410, '스릴': 409, '모든': 291, '봐서': 349, '기억': 142, '이름': 573, '노래': 182, '연인': 514, '웃겨': 543, '아이': 447, '내내': 171, '먹': 282, '해서': 773, '했는데': 775, '함': 768, '겁나': 98, '지루해': 689, '여자': 507, '보니': 333, '울': 541, '개연': 87, '장': 618, '당신': 201, '여배우': 505, '거기': 91, '가서': 64, '나오는': 159, 'ost': 41, '제목': 657, '지금': 685, '얘기': 467, '100': 22, '가는': 61, '슬픔': 413, '비디오': 364, '재밌다': 634, '이지': 585, '그러나': 127, '좋아': 668, '든': 230, '시나리오': 416, '싶은': 428, '5': 26, '조폭': 662, '영화로': 522, '세상': 394, '친구': 719, '영상': 519, '봤는데': 352, '주': 673, '좋고': 666, '이상': 577, '부분': 359, '있지만': 606, '진행': 694, '알았는데': 460, '0': 19, '애니메이션': 464, '재미없고': 623, '귀여운': 118, '아쉬운': 444, '만든다': 266, '말고': 273, '화보': 786, '점점': 650, '이번': 576, '결국': 102, '사회': 373, '사실': 372, '떠나': 240, '실제': 425, '중국': 683, '아까운': 434, '만드는': 264, '최고다': 713, '같은데': 82, 'ㅎ': 53, '뭔': 305, '사건': 368, '진': 691, '이지만': 586, '인간': 591, '가지': 69, '하면서': 757, '그렇게': 129, '이면': 575, '누가': 186, '삶': 377, '주는': 675, '물론': 303, '된다': 224, '망작': 276, '보세요': 338, '키': 726, '스': 408, '때문': 239, '좋았다': 670, '장난': 619, '만화': 269, '만든': 265, '이딴': 564, '라는': 245, '아니고': 438, '확실히': 788, 'ㅡ': 58, '번': 320, '이후': 588, '여기': 504, '한다': 763, '다운': 197, '둘다': 227, '보다가': 335, '됨': 225, '모두': 290, '엔딩': 502, '영화관': 521, '감': 73, '씨': 430, '참고': 703, '반전': 315, '편': 737, '없어서': 486, '평생': 740, '봄': 345, '아오': 446, '상영': 381, '않는다': 456, '미화': 310, '눈물': 188, '없어': 485, '라면': 248, '에서는': 497, '전작': 643, '씬': 431, '맞는': 277, '남녀': 167, '무': 299, '엉': 490, '아저씨': 448, '곳': 106, '희망': 792, '점수': 649, '얼굴': 478, 'b': 37, '보는게': 330, '엄청난': 480, '애니': 463, '통해': 729, '같이': 84, '간만': 71, '준다': 679, '공포': 108, '까진': 149, '머리': 281, '이냐': 561, '혹은': 782, '티': 732, '점도': 648, '자기': 609, '만의': 267, '걸작': 97, '재밌는': 632, '봐': 346, '재미없는': 624, '영화인': 523, '차라리': 701, '실화': 426, '의미': 556, '죽음': 678, '예술': 525, '공포영화': 109, '분위기': 362, '이에요': 580, '좋아하는': 669, '등장': 234, '믿고': 311, '강': 78, '팔': 735, '만하': 268, '군': 115, '7': 27, '특히': 731, '걱정': 92, '설득': 388, '봐야': 350, '평': 738, '접': 651, '장르': 620, '되': 218, '화면': 785, '알았다': 461, '좀비': 665, '기적': 143, '함께': 769, '총': 710, '아쉽다': 445, '팬': 736, '소름': 396, '으로도': 551, '촬영': 711, '시즌': 420, '어휴': 476, '가는줄': 62}\n",
            "['!', '!!', '!!!', '!!!!', '\"', '\"\"', \"'\", '(', ')', ',']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HBAevD6wqyy",
        "outputId": "8b5fc876-c374-4419-e728-601ef288aed1"
      },
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(x_train, y_train)\n",
        "print(\"train score: \", lr.score(x_train, y_train))\n",
        "print(\"test score: \", lr.score(x_test, y_test))"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train score:  0.8555\n",
            "test score:  0.746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgVAx7WUMhgJ"
      },
      "source": [
        "# 불용어 처리\n",
        "- 한국어  불용어 확인은 형태소 분석 라이브러리인 KonLPy 를 이용하면 됨.\n",
        "- (예) 한국어 품사 중 조사를 추출하는 예\n",
        "- pos (part-of-speech): 품사 (명사, 동사, ...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaSnbsAeyFNi"
      },
      "source": [
        "from konlpy.tag import Twitter"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kk98B0mUlsr",
        "outputId": "669a1d9a-8a06-4618-b734-6d1f07391d87"
      },
      "source": [
        "Twitter().morphs(\"텍스트 데이터를 이용해서 불용어 사전을 구축하기 위한 간단 예제\")"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
            "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['텍스트',\n",
              " '데이터',\n",
              " '를',\n",
              " '이용',\n",
              " '해서',\n",
              " '불',\n",
              " '용어',\n",
              " '사전',\n",
              " '을',\n",
              " '구축',\n",
              " '하기',\n",
              " '위',\n",
              " '한',\n",
              " '간단',\n",
              " '예제']"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5_EhfHoWynd",
        "outputId": "4c69e36d-52de-4bca-d104-edf6218acb16"
      },
      "source": [
        "Twitter().pos(\"텍스트 데이터를 이용해서 불용어 사잔을 구축하기 위한 간단 예제\")"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
            "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('텍스트', 'Noun'),\n",
              " ('데이터', 'Noun'),\n",
              " ('를', 'Josa'),\n",
              " ('이용', 'Noun'),\n",
              " ('해서', 'Verb'),\n",
              " ('불', 'Noun'),\n",
              " ('용어', 'Noun'),\n",
              " ('사잔', 'Noun'),\n",
              " ('을', 'Josa'),\n",
              " ('구축', 'Noun'),\n",
              " ('하기', 'Verb'),\n",
              " ('위', 'Noun'),\n",
              " ('한', 'Josa'),\n",
              " ('간단', 'Noun'),\n",
              " ('예제', 'Noun')]"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUC5dkWIXsN3",
        "outputId": "02ce4755-816c-42fc-a0da-10d2d4b9f0cd"
      },
      "source": [
        "Twitter().pos(\"텍스트 데이터를 이용해서 불용어 사전을 구축하기 위한 간단 예제\", norm=True)   # norm - 오타 수정 (사잔->사전)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
            "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('텍스트', 'Noun'),\n",
              " ('데이터', 'Noun'),\n",
              " ('를', 'Josa'),\n",
              " ('이용', 'Noun'),\n",
              " ('해서', 'Verb'),\n",
              " ('불', 'Noun'),\n",
              " ('용어', 'Noun'),\n",
              " ('사전', 'Noun'),\n",
              " ('을', 'Josa'),\n",
              " ('구축', 'Noun'),\n",
              " ('하기', 'Verb'),\n",
              " ('위', 'Noun'),\n",
              " ('한', 'Josa'),\n",
              " ('간단', 'Noun'),\n",
              " ('예제', 'Noun')]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5hJgSwvXQ5T",
        "outputId": "c8b07387-b174-4369-a5d1-90607e677ec9"
      },
      "source": [
        "Twitter().nouns(\"텍스트 데이터를 이용해서 불용어 사전을 구축하기 위한 간단 예제\")"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
            "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['텍스트', '데이터', '이용', '불', '용어', '사전', '구축', '위', '간단', '예제']"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hJQpd451f9-"
      },
      "source": [
        "- norm: 오타수정, stem: 어근 찾기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VziNESMRMhgK",
        "outputId": "2098c7ea-f350-4b19-ba87-d1939b51e929"
      },
      "source": [
        "from konlpy.tag import Twitter\n",
        "\n",
        "word_tags = Twitter().pos(\"텍스트 데이터를 이용해서 불용어 사전을 구축하기 위한 간단 예제\", norm=True, stem=True)\n",
        "print(word_tags)\n",
        "stop_words = [word[0] for word in word_tags if word[1]==\"Josa\"]\n",
        "print (stop_words)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('텍스트', 'Noun'), ('데이터', 'Noun'), ('를', 'Josa'), ('이용', 'Noun'), ('하다', 'Verb'), ('불', 'Noun'), ('용어', 'Noun'), ('사전', 'Noun'), ('을', 'Josa'), ('구축', 'Noun'), ('하다', 'Verb'), ('위', 'Noun'), ('한', 'Josa'), ('간단', 'Noun'), ('예제', 'Noun')]\n",
            "['를', '을', '한']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
            "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsnrMwHXPO1E"
      },
      "source": [
        "# LSTM을 이용한 분석 (additional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIEZcoVsIlXL"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras import utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection, metrics\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os.path\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# 토큰 파서\n",
        "def twitter_tokenizer(text):\n",
        "    return Okt().morphs(text)"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAJKNTfzIRiC"
      },
      "source": [
        "df_train = pd.read_csv('ratings_train.txt', delimiter='\\t', keep_default_na=False)\n",
        "df_test = pd.read_csv('ratings_test.txt', delimiter='\\t', keep_default_na=False)"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otoXoKt9H6QE",
        "outputId": "b1efe888-d25a-43a5-cabf-bd62b6bfab90"
      },
      "source": [
        "print(df_train.shape, df_test.shape)\n",
        "df_train.columns, df_test.columns"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150000, 3) (50000, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Index(['id', 'document', 'label'], dtype='object'),\n",
              " Index(['id', 'document', 'label'], dtype='object'))"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUZvmDtuATmW"
      },
      "source": [
        "df_train, df_test = df_train[:2000], df_test[:1000]  # too big"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8DeUTU5MhgP",
        "outputId": "9cfaa85d-e035-43cc-b836-cc7b0b0de3f2"
      },
      "source": [
        "df_data= pd.concat([df_train, df_test])\n",
        "df_data.shape, df_data.columns"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3000, 3), Index(['id', 'document', 'label'], dtype='object'))"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8zebbzoPO1G"
      },
      "source": [
        "text_data, y_data = df_data['document'].values, df_data['label'].values"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtlGfMtPPO1T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed5dba5-5282-4c52-d79f-8f5911bdf3aa"
      },
      "source": [
        "text_data.shape, y_data.shape"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3000,), (3000,))"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzebNNFjIz68"
      },
      "source": [
        "cv = TfidfVectorizer(tokenizer=twitter_tokenizer, max_features = 1000, min_df=5)"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4EgTHi-PO1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f68f0b6b-ab39-455c-c6f3-45e3088b4a0d"
      },
      "source": [
        "if not os.path.isfile(\"X_data.pickle\"): \n",
        "    print('file does not exists')\n",
        "    X_data = cv.fit_transform(text_data)\n",
        "    pickle.dump(X_data, open(\"X_data.pickle\", \"wb\"))"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file does not exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pviIJR6ZPO1e"
      },
      "source": [
        "# 저장된 tfidf vector 데이터 읽기\n",
        "with open('X_data.pickle', 'rb') as f:\n",
        "    X_data = pickle.load(f)"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-XaJBWGChFs"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3)"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zRdpttZJUGU",
        "outputId": "e78c3143-e520-4fb4-d153-2d0f1f9901a5"
      },
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2100, 1000), (900, 1000), (2100,), (900,))"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI6yem-OPO1q"
      },
      "source": [
        "max_words = X_train.shape[1]   \n",
        "batch_size = 64\n",
        "nb_epoch = 5"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxUfYM-PPO1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42109e08-6c67-4a63-d70d-d6f187f43aa8"
      },
      "source": [
        "# LSTM 학습을 위한 데이터 재배열 (Time step)\n",
        "X_train_rnn = X_train.A.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test_rnn = X_test.A.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "print(X_train_rnn.shape)\n",
        "print(X_test_rnn.shape)"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2100, 1, 1000)\n",
            "(900, 1, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_yPDRa0PO1z"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "\n",
        "def build_LSTM_model():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(128, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2]), return_sequences=True))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(128))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzZ0Jpc0PO13",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "686d931c-ddec-4a08-84fb-4d74ee678c5f"
      },
      "source": [
        "model_lstm = KerasClassifier(build_fn=build_LSTM_model, \n",
        "                             epochs=nb_epoch, \n",
        "                             batch_size=batch_size)\n",
        "model_lstm.fit(X_train_rnn, y_train)"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "33/33 [==============================] - 5s 8ms/step - loss: 0.6927 - accuracy: 0.5186\n",
            "Epoch 2/5\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.6812 - accuracy: 0.7190\n",
            "Epoch 3/5\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.5903 - accuracy: 0.7971\n",
            "Epoch 4/5\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.4170 - accuracy: 0.8267\n",
            "Epoch 5/5\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.3276 - accuracy: 0.8600\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5f35f71bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EzWAnPvPO16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "066c682c-ce33-433b-90a0-0bcefa870c11"
      },
      "source": [
        "y_pred = model_lstm.predict(X_train_rnn)\n",
        "metrics.accuracy_score(y_train, y_pred)"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8938095238095238"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-kT9Gl1KXDm",
        "outputId": "aa9d72a0-afa6-4c19-df25-0b02ca90987e"
      },
      "source": [
        "y_pred = model_lstm.predict(X_test_rnn)\n",
        "metrics.accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7722222222222223"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4v5gvxOL-9a"
      },
      "source": [
        "# 참고사항"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR6pFxYPLx9j"
      },
      "source": [
        "### Pickling: \n",
        "-“Pickling” is the process whereby a Python object hierarchy is converted into a byte stream, and “unpickling” is the inverse operation, whereby a byte stream (from a binary file or bytes-like object) is converted back into an object hierarchy. \n",
        "- Pickling (and unpickling) is alternatively known as “serialization”, “marshalling,” or “flattening”; however, to avoid confusion, the terms “pickling” and “unpickling” are being mostly used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuSvUnE1L7Bb"
      },
      "source": [
        "- Comparison with json\n",
        "  - There are fundamental differences between the pickle protocols and JSON (JavaScript Object Notation):\n",
        "\n",
        "  - JSON is a text serialization format (it outputs unicode text, although most of the time it is then encoded to utf-8), while pickle is a binary serialization format;\n",
        "  - JSON is human-readable, while pickle is not;\n",
        "  - JSON is interoperable and widely used outside of the Python ecosystem, while pickle is Python-specific;\n",
        "  - JSON, by default, can only represent a subset of the Python built-in types, and no custom classes; pickle can represent an extremely large number of Python types (many of them automatically, by clever usage of Python’s introspection facilities; complex cases can be tackled by implementing specific object APIs);\n",
        "  - Unlike pickle, deserializing untrusted JSON does not in itself create an arbitrary code execution vulnerability."
      ]
    }
  ]
}